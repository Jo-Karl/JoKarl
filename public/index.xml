<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title></title>
    <link>/</link>
    <description>Recent content on </description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2018</copyright>
    <lastBuildDate>Sun, 15 Oct 2017 00:00:00 +1300</lastBuildDate>
    <atom:link href="/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Tool Developement</title>
      <link>/post/tool-developement/</link>
      <pubDate>Mon, 29 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/tool-developement/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Introduction to Response Surface Analysis </title>
      <link>/post/introduction-to-response-surface-analysis/</link>
      <pubDate>Sat, 23 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/introduction-to-response-surface-analysis/</guid>
      <description>


&lt;div id=&#34;the-theory&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;The Theory&lt;/h1&gt;
&lt;p&gt;Response Suface Analysis (RSA) is a method from the wider field of Response Surface Methodologies (RSM).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;requirements&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Requirements&lt;/h1&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;Commensurable Scales&lt;/p&gt;
&lt;p&gt;Commensurability explained as briefly as possible is that two scales are measured in the same units. In the world of Likert-scales this mostly means they are measured on the same number of points.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Centered on a Common Point&lt;/p&gt;
&lt;p&gt;There is a number of ways this can be done. The most straight forward is probably to subtract scale midpoint from each participants score. This leaves participants with scores below the theoretical midpoint with negative values and everyone else with positive values.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Participants can indicate high and low values on all scales&lt;/p&gt;
&lt;p&gt;This is more of a scale design than a analysis issue. Here it is important to consider if negatively worded items should need to be included in the scale or if the lowest level of a positively worded item is the lowest score a participant could indicate.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;No Multicolliniearity&lt;/p&gt;
&lt;p&gt;In contrast to the previous requirement this one is actually testable. The easiest way of doing this would be to run a regression with all predictors and examine the Variance Inflation Factors (VIF). An example can be seen below where I predict attractiveness of a landscape from ratings of valence and arousal. valence and arousal are centered around the scale mid-point of 5. VIF values below &lt;strong&gt;5&lt;/strong&gt; are generally considered acceptabily low to conclude that there is no mulitcolliniearity.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;car::vif(lm(attr ~ val_cent + aro_cent, data = data_long))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## val_cent aro_cent 
## 1.016503 1.016503&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;High Power&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div id=&#34;rsa-how-to&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;RSA How-To&lt;/h1&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(&amp;quot;RSA&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Loading required package: lavaan&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## This is lavaan 0.6-1&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## lavaan is BETA software! Please report any bugs.&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Loading required package: lattice&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;rsa_sqd &amp;lt;- RSA(t_attr ~ val_cent * aro_cent, data = data_long, model = &amp;quot;full&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;Computing polynomial model (full) ...&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;summary(rsa_sqd)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## RSA output (package version 0.9.12)
## ===========================================&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning in sqrt(b3 * b5): NaNs produced

## Warning in sqrt(b3 * b5): NaNs produced

## Warning in sqrt(b3 * b5): NaNs produced

## Warning in sqrt(b3 * b5): NaNs produced

## Warning in sqrt(b3 * b5): NaNs produced&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Are there discrepancies in the predictors (with respect to numerical congruence)?
## ----------------------------
## Congruence
## aro_cent &amp;lt; val_cent          Congruence aro_cent &amp;gt; val_cent 
##                75.6                21.7                 2.8 
## 
## Is the full polynomial model significant?
## ----------------------------
## Test on model significance: R^2 = 0.428, p &amp;lt;.001
## 
## 
## Number of observations: n = 180
## ----------------------------
## 
## 
## Regression coefficients for model &amp;lt;full&amp;gt;
## ----------------------------
##                          label    est    se ci.lower ci.upper   beta
## t_attr~1                    b0 42.582 1.120   40.387   44.776  4.270
## t_attr~val_cent             b1  4.001 0.667    2.694    5.308  0.584
## t_attr~aro_cent             b2  0.914 0.540   -0.144    1.972  0.200
## t_attr~val_cent2            b3 -0.027 0.142   -0.306    0.251 -0.016
## t_attr~val_cent_aro_cent    b4 -0.180 0.156   -0.485    0.126 -0.120
## t_attr~aro_cent2            b5  0.190 0.106   -0.017    0.397  0.115
##                            pvalue sig
## t_attr~1                  p &amp;lt;.001 ***
## t_attr~val_cent           p &amp;lt;.001 ***
## t_attr~aro_cent          p = .091   †
## t_attr~val_cent2         p = .848    
## t_attr~val_cent_aro_cent p = .250    
## t_attr~aro_cent2         p = .072   †
## 
## 
## 
## Surface tests (a1 to a5) for model &amp;lt;full&amp;gt;
## ----------------------------
##   label    est    se ci.lower ci.upper   pvalue sig
## 1    a1  4.915 0.787    3.373    6.457  p &amp;lt;.001 ***
## 2    a2 -0.017 0.179   -0.367    0.333 p = .924    
## 3    a3  3.088 0.924    1.277    4.898  p &amp;lt;.001 ***
## 4    a4  0.342 0.240   -0.129    0.813 p = .154    
## 5    a5 -0.217 0.206   -0.621    0.186 p = .291    
## 
## a1: Linear additive effect on line of congruence? YES
## a2: Is there curvature on the line of congruence? NO
## a3: Is the ridge shifted away from the LOC? YES
## a4: Is there a general effect of incongruence? NO
## 
## 
## Location of stationary point for model &amp;lt;full&amp;gt;
## ----------------------------
## val_cent = 31.761; aro_cent = 12.61; predicted t_attr = 111.888
## 
## 
## Principal axes for model &amp;lt;full&amp;gt;
## ----------------------------
##                    label     est      se ci.lower ci.upper   pvalue sig
## Intercept of 1. PA   p10 100.890 189.332 -270.194  471.975 p = .594    
## Slope of 1. PA       p11  -2.779   2.382   -7.449    1.890 p = .243    
## Intercept of 2. PA   p20   1.183   2.439   -3.598    5.964 p = .628    
## Slope of 2. PA       p21   0.360   0.308   -0.245    0.964 p = .243    
##   --&amp;gt; Lateral shift of first PA from LOC at point (0; 0): C1 =  56.696 
##   --&amp;gt; Lateral shift of second PA from LOC at point (0; 0): C2 =  -0.87&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# PLOT THE ESTIMATED MODEL
plot(rsa_sqd, legend=F, param=F,
     axes=c(&amp;quot;LOC&amp;quot;, &amp;quot;LOIC&amp;quot;,&amp;quot;PA1&amp;quot;), 
     project=c(&amp;quot;LOC&amp;quot;, &amp;quot;LOIC&amp;quot;,&amp;quot;PA1&amp;quot;), 
     xlab=&amp;quot;Valence&amp;quot;, ylab=&amp;quot;Arousal&amp;quot;, zlab=&amp;quot;Attractiveness&amp;quot;
     )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-03-23-introduction-to-response-surface-analysis_files/figure-html/RSA-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Rituals, Repetitiveness and Cognitive Load a Competitive Test of Ritual Benefits for Stress.</title>
      <link>/publication/anxiety/</link>
      <pubDate>Fri, 23 Nov 2018 13:06:41 +1300</pubDate>
      
      <guid>/publication/anxiety/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Introduction to R</title>
      <link>/post/r-intro/introduction-to-r/</link>
      <pubDate>Fri, 23 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/r-intro/introduction-to-r/</guid>
      <description>&lt;p&gt;This week I ran two Introduction to R workshops at the Victoria University of Wellington School of Psychology.  If you are interested in downloading the slides you can find them &lt;a href=&#34;https://www.dropbox.com/s/p4gmjqrchk8dm3x/Introduction%20to%20R.pptx?dl=0&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>What&#39;s the deal with omega</title>
      <link>/post/reliability/omega/</link>
      <pubDate>Sun, 07 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/reliability/omega/</guid>
      <description>


&lt;div id=&#34;the-background&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;The Background&lt;/h1&gt;
&lt;p&gt;This post is in essence a summary of McNeish’s &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-McNeish2018&#34;&gt;2018&lt;/a&gt;)&lt;/span&gt; and Raykov and Marcoulides’s &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-Raykov2017&#34;&gt;2017&lt;/a&gt;)&lt;/span&gt; “exchange” on reliability measurement using Cronbach’s alpha. I want to add a few additional perspectives to this topic and provide a short How-To in R.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;what-is-reliability&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;What is reliability&lt;/h1&gt;
&lt;p&gt;Many students might learn what reliability is, but once they reach research praxis they often have forgotten the details and what remains is the &lt;span class=&#34;math inline&#34;&gt;\(\alpha &amp;gt; .70\)&lt;/span&gt; rule. To address this issue first, this rule was not suggested by Cronbach. The cut-off was suggested by Nunnally &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-Nunnally1994&#34;&gt;1994&lt;/a&gt;)&lt;/span&gt;. Let’s see what the original source says:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;“A satisfactory level of reliability depends on how a measure is being used. In the early stages of predictive or construct validation research, time and energy can be saved using instruments that have only modest reliability, e.g., .70. If significant correlations are found, corrections for attenuation will estimate how much the correlations will increase when reliabilities of measures are increased. If these corrected values look promising, it will be worth the time and effort to increase the number of items and reduce much beyond .80 in basic research is often wasteful of time and money. Measurement error attenuates correlations very little at that level. Strenuous and unnecessary efforts at standardization in addition to increasing the number of items might be required to obtain a reliability of, say, .90. In contrast to the standards used to compare groups, a reliability of .80 may not be nearly high enough in making decisions about individuals. Group research is often concerned with the size of correlations and with mean differences among experimental treatments, for which a reliability of .80 is adequate. However, a great deal hinges on the exact test scores when decisions are made about individuals. If, for example, children with IQs below 70 are to be placed in special classes, it may make a great deal of difference whether a child has an IQ of 65 or 75 on a particular test. When selection standards are quite rigorous, decisions depend on very small score differences, and so it is difficult to accept any measurement error. We have noted that the standard error of measurement is almost one-third as large as the overall standard deviation of test scores even when the reliability is .90. If important decisions are made with respect to specific test scores, a reliability of .90 is the bare minimum, and a reliability of .95 should be considered the desirable standard. However, never switch to a less valid measure simply because it is more reliable.” (pp.264)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;To boil down what Nunnally said; reliability can never replace validity, the reliability your measure should achieve is dependent on the context of application. The commonly applied rule of .70 is fitting for some contexts. Specifically contexts where one wants to save time and effort. Lance, Butts, and Michels &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-Lance2006&#34;&gt;2006&lt;/a&gt;)&lt;/span&gt; make the important point that this is not a context that applies in most published papers. In most contexts we would want &lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt; to be over .80 and over .90 | .95 if we make judgments about individuals based on this test, such as personality questionnaires used for hiring.&lt;/p&gt;
&lt;p&gt;In the discussion on the applicability of &lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt; Nunnally makes statements such as:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;“Coefficient a usually provides a good estimate of reliability because sampling of content is usually the major source of measurement error for static constructs and also because it is sensitive to the”sampling&amp;quot; of situational factors as well as item content.&amp;quot; (p.252)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;But what is the “usual” case which Nunnally assumes. We could assume that it is the case in which the underlying assumption of &lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt; are met. Let’s have a look at these assumptions to better appreciate Nunnally’s usual case. I am paraphrasing in this section from the excellent article by McNeish &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-McNeish2018&#34;&gt;2018&lt;/a&gt;)&lt;/span&gt; and I highly recommend reading it for a more detailed discussion.&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;The scale is uni-dimensional.&lt;/li&gt;
&lt;li&gt;Scale items are on a continuous scale and normally distributed.&lt;/li&gt;
&lt;li&gt;The scale adheres to tau equivalence.&lt;/li&gt;
&lt;li&gt;The errors of the items do not covary.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Let’s step through a normal scale we could find in our data, such as well-being. Participants answered a scale on flourishing and a scale on satisfaction with life. Because we are interested in overall well-being, we decided to combine the individual items into a single score.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;wll &amp;lt;- c(&amp;quot;swls_1&amp;quot;, &amp;quot;swls_2&amp;quot;, &amp;quot;swls_3&amp;quot;, &amp;quot;swls_4&amp;quot;, &amp;quot;swls_5&amp;quot;, &amp;quot;flourishing_1&amp;quot;,
&amp;quot;flourishing_2&amp;quot;, &amp;quot;flourishing_3&amp;quot;, &amp;quot;flourishing_4&amp;quot;,
&amp;quot;flourishing_5&amp;quot;, &amp;quot;flourishing_6&amp;quot;, &amp;quot;flourishing_7&amp;quot;, &amp;quot;flourishing_8&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s get the theoretical assumpitions out of the way first. Regarding assumption 1, we know that the scale is not uni-dimensional, because it is made up from two distinct scales. We can support this looking at the scree plot below (the paralell analysis would show one factor, but for the sake of argument let’s assume the scree is right.)&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/Reliability/omega_files/figure-html/paralelle-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;So we can see we already violate one assumption of Cronbach’s &lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt;. You can see similar things in many publications that first report the reliability of facets (e.g. mindfulness) and then report the overall reliability.&lt;/p&gt;
&lt;p&gt;Assumption 2 can be split into the requirement that the data is continous, which Likert-type scales are arguably not &lt;span class=&#34;citation&#34;&gt;(for disagreeing stances see: Norman &lt;a href=&#34;#ref-Norman2010&#34;&gt;2010&lt;/a&gt;; Carifio and Perla &lt;a href=&#34;#ref-Carifio2007&#34;&gt;2007&lt;/a&gt;)&lt;/span&gt;. For brevities sake I avoid this discussion for now, on the other hand we can assess normality of our data quite easily. As shown below none of our items is normally distributed.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;##            Test      Variable Statistic   p value Normality
## 1  Shapiro-Wilk    swls_1        0.9280  &amp;lt;0.001      NO    
## 2  Shapiro-Wilk    swls_2        0.8924  &amp;lt;0.001      NO    
## 3  Shapiro-Wilk    swls_3        0.9018  &amp;lt;0.001      NO    
## 4  Shapiro-Wilk    swls_4        0.9118  &amp;lt;0.001      NO    
## 5  Shapiro-Wilk    swls_5        0.9215  &amp;lt;0.001      NO    
## 6  Shapiro-Wilk flourishing_1    0.9110  &amp;lt;0.001      NO    
## 7  Shapiro-Wilk flourishing_2    0.8474  &amp;lt;0.001      NO    
## 8  Shapiro-Wilk flourishing_3    0.9130  &amp;lt;0.001      NO    
## 9  Shapiro-Wilk flourishing_4    0.8905  &amp;lt;0.001      NO    
## 10 Shapiro-Wilk flourishing_5    0.8707  &amp;lt;0.001      NO    
## 11 Shapiro-Wilk flourishing_6    0.8644  &amp;lt;0.001      NO    
## 12 Shapiro-Wilk flourishing_7    0.8700  &amp;lt;0.001      NO    
## 13 Shapiro-Wilk flourishing_8    0.8810  &amp;lt;0.001      NO&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Assumption 3 is also something we can test quite easily using SEM. We would just compare the fit of the unrestricted model to a model that restricts the loadings of all items on the latent variable to be identical. If we find no substantial decrease in fit we could conclude that we have tau-equivalence. There is also a number of packages that allow you to test for tau-equivalence of your data such as the coefficientalpha package (Which does not seem to be still actively developed and has not the best documentation for functions). In our current case we do not have tau-equivalence.&lt;/p&gt;
&lt;p&gt;Assumption 4 is again something that could be easily assessed using a SEM approach. For brevities sake I will omit this, as I think my point is clear. In essence, many commonly used scales violate the assumptions of &lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt;. And independent of the size of the impact we should strife to use as fitting methods as possible.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;alternatives&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Alternatives&lt;/h1&gt;
&lt;p&gt;So what are the alternatives to alpha. First I do not think that we need to replace alpha for now Raykov and Marcoulides &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-Raykov2017&#34;&gt;2017&lt;/a&gt;)&lt;/span&gt; make some interesting points on its contiued usage. So instead of replacing it, we could try supplementing it. Alternatives suggested by McNeish &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-McNeish2018&#34;&gt;2018&lt;/a&gt;)&lt;/span&gt; are omega total, and GLB. So how would we compute those reliabilities. We have a number of options from different packages, such as the &lt;em&gt;psych&lt;/em&gt; package.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;psy_omega &amp;lt;- psych::omega(dat[wll], nfactors = 2, poly = F)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/Reliability/omega_files/figure-html/omega-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;psy_omega&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Omega 
## Call: psych::omega(m = dat[wll], nfactors = 2, poly = F)
## Alpha:                 0.93 
## G.6:                   0.94 
## Omega Hierarchical:    0.81 
## Omega H asymptotic:    0.86 
## Omega Total            0.94 
## 
## Schmid Leiman Factor loadings greater than  0.2 
##                  g   F1*   F2*   h2   u2   p2
## swls_1        0.69        0.41 0.64 0.36 0.74
## swls_2        0.64        0.33 0.52 0.48 0.79
## swls_3        0.76        0.41 0.74 0.26 0.78
## swls_4        0.65        0.36 0.55 0.45 0.76
## swls_5        0.55        0.30 0.39 0.61 0.77
## flourishing_1 0.72  0.27       0.60 0.40 0.85
## flourishing_2 0.67  0.33       0.56 0.44 0.80
## flourishing_3 0.68  0.39       0.62 0.38 0.76
## flourishing_4 0.59  0.36       0.48 0.52 0.73
## flourishing_5 0.65  0.43       0.62 0.38 0.69
## flourishing_6 0.76  0.37       0.71 0.29 0.80
## flourishing_7 0.69  0.35       0.60 0.40 0.79
## flourishing_8 0.65  0.37       0.56 0.44 0.76
## 
## With eigenvalues of:
##    g  F1*  F2* 
## 5.86 1.05 0.69 
## 
## general/max  5.59   max/min =   1.51
## mean percent general =  0.77    with sd =  0.04 and cv of  0.05 
## Explained Common Variance of the general factor =  0.77 
## 
## The degrees of freedom are 53  and the fit is  0.5 
## The number of observations was  393  with Chi Square =  191.65  with prob &amp;lt;  1.4e-17
## The root mean square of the residuals is  0.03 
## The df corrected root mean square of the residuals is  0.04
## RMSEA index =  0.083  and the 10 % confidence intervals are  0.069 0.094
## BIC =  -124.97
## 
## Compare this with the adequacy of just a general factor and no group factors
## The degrees of freedom for just the general factor are 65  and the fit is  1.34 
## The number of observations was  393  with Chi Square =  515.94  with prob &amp;lt;  2.1e-71
## The root mean square of the residuals is  0.1 
## The df corrected root mean square of the residuals is  0.11 
## 
## RMSEA index =  0.134  and the 10 % confidence intervals are  0.122 0.144
## BIC =  127.65 
## 
## Measures of factor score adequacy             
##                                                  g   F1*   F2*
## Correlation of scores with factors            0.90  0.64  0.63
## Multiple R square of scores with factors      0.82  0.41  0.39
## Minimum correlation of factor score estimates 0.63 -0.19 -0.22
## 
##  Total, General and Subset omega for each subset
##                                                  g  F1*  F2*
## Omega total for total scores and subscales    0.94 0.92 0.87
## Omega general for total scores and subscales  0.81 0.72 0.66
## Omega group for total scores and subscales    0.12 0.20 0.20&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I personally prefer the &lt;em&gt;userfriendlyscience&lt;/em&gt; package, which containts the niffty reliability function.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sci_omega &amp;lt;- userfriendlyscience::reliability(dat[wll])&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Information about this analysis:
## 
##                  Dataframe: data
##                      Items: swls_1, swls_2, swls_3, swls_4, swls_5, flourishing_1, flourishing_2, flourishing_3, flourishing_4, flourishing_5, flourishing_6, flourishing_7, flourishing_8
##               Observations: 393
##      Positive correlations: 78 out of 78 (100%)
## 
## Estimates assuming interval level:
## 
##              Omega (total): 0.93
##       Omega (hierarchical): 0.81
##    Revelle&amp;#39;s omega (total): 0.95
## Greatest Lower Bound (GLB): 0.95
##              Coefficient H: 0.94
##           Cronbach&amp;#39;s alpha: 0.93
## Confidence intervals:
##              Omega (total): [0.92, 0.94]
##           Cronbach&amp;#39;s alpha: [0.92, 0.94]
## 
## Estimates assuming ordinal level:
## 
##      Ordinal Omega (total): 0.94
##  Ordinal Omega (hierarch.): 0.93
##   Ordinal Cronbach&amp;#39;s alpha: 0.94
## Confidence intervals:
##      Ordinal Omega (total): [0.93, 0.95]
##   Ordinal Cronbach&amp;#39;s alpha: [0.93, 0.94]
## 
## Note: the normal point estimate and confidence interval for omega are based on the procedure suggested by Dunn, Baguley &amp;amp; Brunsden (2013) using the MBESS function ci.reliability, whereas the psych package point estimate was suggested in Revelle &amp;amp; Zinbarg (2008). See the help (&amp;#39;?scaleStructure&amp;#39;) for more information.&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level1 unnumbered&#34;&gt;
&lt;h1&gt;References&lt;/h1&gt;
&lt;div id=&#34;refs&#34; class=&#34;references&#34;&gt;
&lt;div id=&#34;ref-Carifio2007&#34;&gt;
&lt;p&gt;Carifio, James, and Rocco J Perla. 2007. “Ten Common Misunderstandings, Misconceptions, Persistent Myths and Urban Legends about Likert Scales and Likert Response Formats and their Antidotes.” &lt;em&gt;Journal of Social Sciences&lt;/em&gt; 3 (3): 106–16. &lt;a href=&#34;https://thescipub.com/PDF/jssp.2007.106.116.pdf&#34; class=&#34;uri&#34;&gt;https://thescipub.com/PDF/jssp.2007.106.116.pdf&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-Lance2006&#34;&gt;
&lt;p&gt;Lance, C. E., Marcus M. Butts, and Lawrence C. Michels. 2006. “The Sources of Four Commonly Reported Cutoff Criteria: What Did They Really Say?” &lt;em&gt;Organizational Research Methods&lt;/em&gt; 9 (2). SAGE Publications: 202–20. doi:&lt;a href=&#34;https://doi.org/10.1177/1094428105284919&#34;&gt;10.1177/1094428105284919&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-McNeish2018&#34;&gt;
&lt;p&gt;McNeish, Daniel. 2018. “Thanks coefficient alpha, we’ll take it from here.” &lt;em&gt;Psychological Methods&lt;/em&gt; 23 (3): 412–33. doi:&lt;a href=&#34;https://doi.org/10.1037/met0000144&#34;&gt;10.1037/met0000144&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-Norman2010&#34;&gt;
&lt;p&gt;Norman, Geoff. 2010. “Likert scales, levels of measurement and the ‘laws’ of statistics.” &lt;em&gt;Advances in Health Sciences Education&lt;/em&gt; 15 (5): 625–32. doi:&lt;a href=&#34;https://doi.org/10.1007/s10459-010-9222-y&#34;&gt;10.1007/s10459-010-9222-y&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-Nunnally1994&#34;&gt;
&lt;p&gt;Nunnally, J.C., and I.H. Bernstein. 1994. “The Assessment of Reliability.” In &lt;em&gt;Psychometric Theory&lt;/em&gt;, 3rd ed., 248–92.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-Raykov2017&#34;&gt;
&lt;p&gt;Raykov, Tenko, and George A. Marcoulides. 2017. “Thanks Coefficient Alpha, We Still Need You!” &lt;em&gt;Educational and Psychological Measurement&lt;/em&gt;, August. SAGE PublicationsSage CA: Los Angeles, CA, 001316441772512. doi:&lt;a href=&#34;https://doi.org/10.1177/0013164417725127&#34;&gt;10.1177/0013164417725127&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Withing and Between-Subjects Errors</title>
      <link>/post/errors/withing-and-between-subjects-errors/</link>
      <pubDate>Sun, 07 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/errors/withing-and-between-subjects-errors/</guid>
      <description>


&lt;p&gt;This is a very short post in which I want to highlight, because I realized that the issue is often overlooked by students when writing up their data. Today I want to highlight the difference between within- and between-subjects errors (With code examples).&lt;/p&gt;
&lt;p&gt;Imagine you have data like this example below. Participants responded to a number of mindfulness items multiple times during the day over the duration of a week. For simplicity, I will only focus on days and not events during the day.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 8
##   number   day sms_1 sms_2 sms_3 sms_4 sms_5 sms_6
##    &amp;lt;int&amp;gt; &amp;lt;int&amp;gt; &amp;lt;int&amp;gt; &amp;lt;int&amp;gt; &amp;lt;int&amp;gt; &amp;lt;int&amp;gt; &amp;lt;int&amp;gt; &amp;lt;int&amp;gt;
## 1  18072     1     8     9     8     8     8     8
## 2  18072     1     8     8     8     8     9     8
## 3  18072     1     8     8     6     9     9     9
## 4  18072     1     6     7     6     8     9     9
## 5  18072     3     7     7     7     8     8     8
## 6  18072     3     8     8     8     8     8     8&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;A natural first instinct if you have similar data would be to compute the means and standard errors, which would be fine if each row would be an independent observation. In our case this is not the case each participant answered seven surveys and the distinct possibility exists that some of the variance might be due to difference between participants. In R there is an easy way to account for this &lt;span class=&#34;citation&#34;&gt;(if you want to read more on the theoretical background I recommend Morey &lt;a href=&#34;#ref-Morey2008&#34;&gt;2008&lt;/a&gt;; Franz and Loftus &lt;a href=&#34;#ref-Franz2012&#34;&gt;2012&lt;/a&gt;; Cousineau &lt;a href=&#34;#ref-Cousineau2017&#34;&gt;2017&lt;/a&gt;)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;The first function (&lt;em&gt;Rmisc::summarySE&lt;/em&gt;) computes errors without considering that the observations are not independent. The second function (&lt;em&gt;Rmisc::summarySEwithin&lt;/em&gt;) computes the errors accounting for the non-independent nature of the observations. We can now see that after only three days of journaling participants report higher scores of mindfulness, whereas using between-subjects errors we would conclude that there is no difference between the values on the third day and the baseline.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;between &amp;lt;- Rmisc::summarySE(data = data_long, measurevar = &amp;quot;sms&amp;quot;,
                            groupvars = &amp;quot;day&amp;quot;)

within &amp;lt;- Rmisc::summarySEwithin(data = data_long, measurevar = &amp;quot;sms&amp;quot;,
                                 withinvars = &amp;quot;day&amp;quot;,
                                 idvar = &amp;quot;number&amp;quot;)

within$day &amp;lt;- as.integer(within$day)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Plotting the two different solutions, we can clearly see the difference. The between-subjects errors are in black and the within-subjects errors are in red. The within-subjects errors are considerably smaller as a result of accounting for the non-independence.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(between, aes(x = factor(day), y = sms, group = 1)) +
  geom_line(stat = &amp;quot;identity&amp;quot;) +
  geom_point() +
  geom_errorbar(aes(ymin = sms - ci, ymax = sms + ci)) +
  geom_errorbar(aes(ymin = sms - ci, ymax = sms + ci,
                    colour = &amp;quot;red1&amp;quot;), data = within) +
  guides(colour = FALSE) + 
  labs(x = &amp;quot;Day&amp;quot;, y = &amp;quot;Short Mindfulness Scale&amp;quot;) +
  theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/Errors/2018-11-07-withing-and-between-subjects-errors_files/figure-html/plotting-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;div id=&#34;refs&#34; class=&#34;references&#34;&gt;
&lt;div id=&#34;ref-Cousineau2017&#34;&gt;
&lt;p&gt;Cousineau, Denis. 2017. “Varieties of Confidence Intervals.” &lt;em&gt;Advances in Cognitive Psychology&lt;/em&gt; 13 (2). University of Finance; Management in Warsaw: 140–55. doi:&lt;a href=&#34;https://doi.org/10.5709/acp-0214-z&#34;&gt;10.5709/acp-0214-z&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-Franz2012&#34;&gt;
&lt;p&gt;Franz, Volker H, and Geoffrey R Loftus. 2012. “Standard errors and confidence intervals in within-subjects designs: generalizing Loftus and Masson (1994) and avoiding the biases of alternative accounts.” &lt;em&gt;Psychonomic Bulletin &amp;amp; Review&lt;/em&gt; 19 (3). Springer: 395–404. doi:&lt;a href=&#34;https://doi.org/10.3758/s13423-012-0230-1&#34;&gt;10.3758/s13423-012-0230-1&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-Morey2008&#34;&gt;
&lt;p&gt;Morey, Richard D. 2008. “Confidence Intervals from Normalized Data: A correction to Cousineau (2005).” &lt;em&gt;Tutorials in Quantitative Methods for Psychology&lt;/em&gt; 4 (2): 61–64. doi:&lt;a href=&#34;https://doi.org/10.20982/tqmp.04.2.p061&#34;&gt;10.20982/tqmp.04.2.p061&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Multi-dimensional scaling in R</title>
      <link>/post/mds/smacof/</link>
      <pubDate>Fri, 20 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/mds/smacof/</guid>
      <description>
&lt;script src=&#34;/rmarkdown-libs/htmlwidgets/htmlwidgets.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;/rmarkdown-libs/plotly-binding/plotly.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;/rmarkdown-libs/typedarray/typedarray.min.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;/rmarkdown-libs/jquery/jquery.min.js&#34;&gt;&lt;/script&gt;
&lt;link href=&#34;/rmarkdown-libs/crosstalk/css/crosstalk.css&#34; rel=&#34;stylesheet&#34; /&gt;
&lt;script src=&#34;/rmarkdown-libs/crosstalk/js/crosstalk.min.js&#34;&gt;&lt;/script&gt;
&lt;link href=&#34;/rmarkdown-libs/plotly-htmlwidgets-css/plotly-htmlwidgets.css&#34; rel=&#34;stylesheet&#34; /&gt;
&lt;script src=&#34;/rmarkdown-libs/plotly-main/plotly-latest.min.js&#34;&gt;&lt;/script&gt;


&lt;div id=&#34;mds-basics&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;MDS basics&lt;/h1&gt;
&lt;p&gt;This post focuses on MDS (Also sometimes called smallest space analysis (Guttman, 1968) or multidimensional similarity structure analysis (Borg &amp;amp; Lingoes, 1987)) as exploratory tool and a large amount of the information is lifted from Borg and Gronen (2005) which I really recommend for further readings.&lt;/p&gt;
&lt;p&gt;Exploratory MDS might seem at first glance like tea-leaf reading, but over the years several rules have been developed that aid in determining structure from the MDS plots.&lt;/p&gt;
&lt;p&gt;In the case I will talk about during this post we were interested in discovering how different measures of mindfulness, personality, and approach/ avoidance motivation are related to each other. To this extent participants answered statements about themselves on Likert-scales related to these concepts. An important concept in MDS is distance. The idea behind distance is that individuals reproduce mental distances between concepts when asked about dissimilarities between the concepts. To cite directly form Borg and Gronen (2005):&lt;/p&gt;
&lt;p&gt;“The most common approach is to hypothesize that a person, when asked about the dissimilarity of pairs of objects from a set of objects, acts as if he or she computes a distance in his or her “psychological space” of these objects.”&lt;/p&gt;
&lt;p&gt;In our case participants were not asked to rate dissimilarities between the measures, but rather rate themselves on these measures. Nevertheless, if we think about it these self-ratings can also represent psychological distances. A participant that scores high on avoidance behaviour might also score high on anxiety, but score low on approach behaviour. These differences can be represented as psychological distances with avoidance behaviour and anxiety being in close proximity and approach behaviour being distal from those two concepts. ## Comparing MDS and PCA&lt;/p&gt;
&lt;p&gt;Mathematically and conceptually, there are large similarities between MDS and Principal components analysis (PCA) or factor analysis. PCA is more focused on the dimensions themselves, and seek to maximize explained variance, whereas MDS is more focused on relations among the scaled objects.&lt;/p&gt;
&lt;div id=&#34;correlations-and-mds&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Correlations and MDS&lt;/h2&gt;
&lt;p&gt;Data obtained from answers to Likert scales can not directly be considered as distances, but the correlation coefficients between multiple columns can. Correlations are appropriate for MDS.&lt;/p&gt;
&lt;div id=&#34;obtaining-a-distance-matrix-from-a-correlation-matrix.&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Obtaining a distance matrix from a correlation matrix.&lt;/h3&gt;
&lt;p&gt;The &lt;em&gt;psych&lt;/em&gt; package provides a handy function (&lt;em&gt;cor2dist&lt;/em&gt;) to transform a correlation matrix into a distance matrix. In the background this simple function is performed: &lt;span class=&#34;math display&#34;&gt;\[\sqrt{2 * (1 - x)}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Pipelines provide a handy way of reducing the number of objects stored in the work space if they are not used in later analysis. In my current case I used the different measures of interested (Mindfulness facets, personality, etc.) and labeled the facets. The first line produces the correlation between the variables, the second line selects only the correlation coefficients from the output, and the second line converts them into a distance matrix which is returned as an object labelled distance.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;distance &amp;lt;- psych::corr.test(mnd_test[,facets]) %&amp;gt;%
  .$r %&amp;gt;%
  psych::cor2dist()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So why even bother with transforming correlation coefficients into distances? The reason for this can be found in the assumptions about a geometrical plane. The first assumption is called non-negativity and can be expressed as: &lt;span class=&#34;math display&#34;&gt;\[d_{ii} = d_{jj} = 0 ≤ d_{ij}\]&lt;/span&gt; Simply put on plane the the distance between any two points &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt; is greater than 0 or equal to 0 (if &lt;span class=&#34;math inline&#34;&gt;\(i = j\)&lt;/span&gt;). This presents the first reason why correlation coefficients can not directly used as input for a MDS, because they can be negative. The second assumption called symmetry is self-explanatory: &lt;span class=&#34;math display&#34;&gt;\[d_{ij} = d_{ji}\]&lt;/span&gt; For an MDS it is necessary that the distance between &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt; is identical to the distance between &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Last is the triangle inequality: &lt;span class=&#34;math display&#34;&gt;\[d_{ij} ≤ d_{ik} + d_{kj}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;This triangle inequality says that going directly from &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; to &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt; will never be farther than going from &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; to &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt; via an intermediate point &lt;span class=&#34;math inline&#34;&gt;\(k\)&lt;/span&gt;. If &lt;span class=&#34;math inline&#34;&gt;\(k\)&lt;/span&gt; happens to be on the way, then the function is an equality.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;evaluating-stress&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Evaluating stress&lt;/h2&gt;
&lt;p&gt;Rather then goodness-of-fit indicators MDS uses a badness-of-fit indicator, &lt;em&gt;stress&lt;/em&gt;. Stress is the normed sum of squares aggregating the representation errors of the model compared to the underlying data. In an applied context we rarely examine the raw stress scores as it is dependent on the scale used. Rather we use a value to judge badness-of-fit that is called Stress-1 or &lt;span class=&#34;math inline&#34;&gt;\(\sigma_1\)&lt;/span&gt; 1 (Kruskal, 1964a). If you are interested, below is the formula for &lt;span class=&#34;math inline&#34;&gt;\(\sigma_1\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\sigma_1(X) = \sqrt{\frac{\sum{[f(p_{ij}) - d_{ij}(X)]^2}}{\sum{d_{ij}^{2}(X)}}}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;One important property of &lt;span class=&#34;math inline&#34;&gt;\(\sigma_1\)&lt;/span&gt; is that missing data is skipped in the process of summing up the representation errors. The more missing data is present the lower the stress value will be. This is probably less a problem if you are working with correlations derived from underlying data, but can be a problem if you are working with values obtained from other sources.&lt;/p&gt;
&lt;p&gt;From the presented formula we can derive that if we perfectly represent the underlying data &lt;span class=&#34;math inline&#34;&gt;\(\sigma_1\)&lt;/span&gt; will be 0 and the greater the deviation gets the greater &lt;span class=&#34;math inline&#34;&gt;\(\sigma_1\)&lt;/span&gt; becomes.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;determening-the-correct-number-of-dimensions&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Determening the correct number of dimensions&lt;/h2&gt;
&lt;p&gt;All data can be represented in a MDS with 0 stress in &lt;span class=&#34;math inline&#34;&gt;\(m = n -2\)&lt;/span&gt; dimensions, where &lt;span class=&#34;math inline&#34;&gt;\(m\)&lt;/span&gt; is the number of dimensions and &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; is the number of variables included in the MDS. Borg and Gronen again express this dilemma in a very succinct way :&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;“However, such perfect solutions are not desired, as we saw above. Therefore, one seeks an MDS representation with considerably fewer dimensions. The problem is how to choose the “proper” dimensionality. Scaling with too few dimensions may distort the true (reliable) MDS structure due to over-compression or may lead to technical problems. Being too generous on dimensions may, on the other hand, blur the MDS structure due to overfitting noise components.”&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;As everything in MDS the decision on the number of dimensions is largely up to the researcher and while universal rules of thumb are hard to give several methods have been developed to assists applied researchers to determine the correct number of dimensions.&lt;/p&gt;
&lt;p&gt;One method should be familiar to anyone that uses factor analysis on the regular, the scree plot (Or parallel analysis). The goal is to fin a solution “for which further increase in [m] does not significantly reduce Stress” (Kruskal, 1964a, p. 16). The simplest way to do this is computing the &lt;span class=&#34;math inline&#34;&gt;\(\sigma_1\)&lt;/span&gt; for each m-dimensional solution and plotting it against the number of dimensions. This can easily be done in R using many different approaches, below is a very lazy implementation with a for loop.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;## The for loop runs the MDS function for the amount of variables in the set - 1. 
for(ii in 1:(length(facets) - 1)){
            distance_MDS &amp;lt;- smacof::mds(distance, ndim = ii,
                                        type =   &amp;quot;ordinal&amp;quot;)
            randomstress &amp;lt;- smacof::randomstress(37, ndim = ii, nrep = 10,
                                                 type = &amp;quot;ordinal&amp;quot;)
            randomstress_value[ii] &amp;lt;- mean(randomstress)
            stress_values[ii] &amp;lt;- distance_MDS$stress
}
## Here I just add a second column that contains the number of dimension corresponding to the stress value.
stress_plot &amp;lt;- cbind(stress = stress_values,
                     dimension = seq(1:(length(facets) - 1)),
                     random_stress = randomstress_value) %&amp;gt;% 
                     as.data.frame() %&amp;gt;%
                     gather(., key = &amp;quot;type&amp;quot;, value = &amp;quot;stress&amp;quot;, -&amp;quot;dimension&amp;quot;)
stress_plot$diff &amp;lt;- ave(stress_plot$stress, stress_plot$type,
                        FUN = function(x) c(0, abs(diff(x))))
  


## Last, I plot the number of dimensions on the x-axis and the stress-1 value on the y axis.

stress_plot %&amp;gt;%
  ggplot() +
  aes(x = dimension, y = stress, colour = type) +
  geom_point() +
  geom_line() +
  theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/MDS_files/figure-html/scree-1.png&#34; width=&#34;672&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;This plot can be inspected to determine the appropriate number of dimensions. As you can see stress is monotonically decreasing with increasing dimensionality. At the start a step decline occurs and after a certain point stress decreases only marginally with increasing dimensionality. A commonly applied interpretation is to look for the &lt;em&gt;elbow&lt;/em&gt; of the scree plot, where decreases in stress become less pronounced. The rationale of this choice is that the elbow marks the point where MDS uses additional dimensions to essentially only scale the noise in the data, after having succeeded in representing the systematic structure in the given dimensionality m.&lt;/p&gt;
&lt;p&gt;I find it also quite useful to look at the distance in stress between &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(n + 1\)&lt;/span&gt;. The plot below plots the difference in stress for each dimension in respect to the previous dimension (It is obviously 0 for the first dimension, therefore the plot starts with &lt;span class=&#34;math inline&#34;&gt;\(n = 2\)&lt;/span&gt;). We can see that the difference between &lt;span class=&#34;math inline&#34;&gt;\(n = 1\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(n = 2\)&lt;/span&gt; is similar in real and simulated data. The pattern remains the same in real and simulated data until &lt;span class=&#34;math inline&#34;&gt;\(n= 5\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(n = 6\)&lt;/span&gt;. At this point we see a clear deviation in the real data from the pattern in the random data. This could indicate that this could be considered the point of inflection.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;stress_plot %&amp;gt;%
  ggplot() +
  aes(x = dimension, y = diff, colour = type, group = type) +
  geom_point() +
  geom_step() +
  xlim(2, max(stress_plot$dimension)) +
  theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/MDS_files/figure-html/alternative-1.png&#34; width=&#34;672&#34; style=&#34;display: block; margin: auto;&#34; /&gt; I mentioned parallel analysis above. Some simulation studies on stress obtained from random data based on different &lt;em&gt;n&lt;/em&gt; and &lt;em&gt;m&lt;/em&gt; were conducted in the past (Cliff, 1973; Knoll, 1969; Klahr, 1969; Spence and Ogilvie, 1973). It might be promising to implent an approach that mirrors parallel analysis for stress values.&lt;/p&gt;
&lt;p&gt;In our current example this point could be point 4 based on the stress plot or 5/6 based on looking at drop in stress. A further problem that needs to be considered in MDS that if one intends to plot the resulting graph dimensions above 3 are hard to display and visually interpret. This makes trade offs between the goal of MDS, uncovering and visualising data structures, and statistical rigor necessary. I would use 3 dimensions, as they can still be visualised and their &lt;span class=&#34;math inline&#34;&gt;\(\sigma_1\)&lt;/span&gt; = 0.11 is low enough to assume acceptable representation of the underlying data.&lt;/p&gt;
&lt;p&gt;So what is a acceptable stress value? Often quoted or rather misquoted at this point is Guttman (in Porrat, 1974). If you have a look online and even in some publications authors report that &lt;span class=&#34;math inline&#34;&gt;\(\sigma_1 &amp;lt;= .15\)&lt;/span&gt; represents a good value for an acceptably precise ordinal MDS solution. Citing again from Borg and Gronen:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;“[H]e required that the coefficient of alienation K [which is similar but not identical to Stress] should be less than 0.15 for an acceptably precise MDS solution. He later added that what he had in mind when he made this proposal were “the usual circumstances”(Guttman, personal communication).”&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The usual circumstances are where the number of items clearly exceeds the number of dimensions (sometimes suggested as &lt;span class=&#34;math inline&#34;&gt;\(n &amp;gt; m * 4\)&lt;/span&gt;). Further if &lt;span class=&#34;math inline&#34;&gt;\(n &amp;gt; m * 10\)&lt;/span&gt; larger values than .15 are acceptable. I did a small literature search, but could not find any studies that directly compared the coefficient of alienation K to &lt;span class=&#34;math inline&#34;&gt;\(\sigma_1\)&lt;/span&gt;. In my view it is unclear how well the .15 rule translates between those measures.&lt;/p&gt;
&lt;p&gt;Other authors developed recommendations based on experience for &lt;span class=&#34;math inline&#34;&gt;\(\sigma_1\)&lt;/span&gt;. The following part from Borg and Gronen highlight an exceptionally important point about those cut-offs:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;“For the Stress-1 coefficient σ1 using ordinal MDS, Kruskal (1964a), on the basis of his “experience with experimental and synthetic data” (p. 16), suggests the following benchmarks: .20 = poor, .10 = fair, .05 = good, .025 = excellent, and .00 = perfect. Unfortunately, such criteria almost inevitably lead to misuse by suggesting that only solutions whose Stress is less than .20 are acceptable, or that all solutions with a Stress of less than .05 are good in more than just a formal sense. Neither conclusion is correct. An MDS solution may have high Stress simply as a consequence of high error in the data, and finding a precise representation for the data does not imply anything about its scientific value.”&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;We can see in the stress plot that we could further reduce &lt;span class=&#34;math inline&#34;&gt;\(\sigma_1\)&lt;/span&gt; and increase the granularity of our analysis if we increase the number of dimensions. On the other hand we might sacrifice interpretability of the final solution. If you are interested in the analysis with a greater number of dimensions, feel free to use the underlying data.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;plotting-the-solution&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Plotting the solution&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;MDS &amp;lt;- smacof::mds(distance, type = &amp;quot;ordinal&amp;quot;, ndim = 3)
coordinates &amp;lt;- as.data.frame(MDS$conf) %&amp;gt;%
  tibble::rownames_to_column()
library(plotly)
p &amp;lt;- plot_ly(coordinates,
                     x = ~D1,
                     y = ~D2,
                     z = ~D3) %&amp;gt;%
  add_markers(name = ~rowname,
              opacity = .80)
  
p&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;htmlwidget-1&#34; style=&#34;width:960px;height:1152px;&#34; class=&#34;plotly html-widget&#34;&gt;&lt;/div&gt;
&lt;script type=&#34;application/json&#34; data-for=&#34;htmlwidget-1&#34;&gt;{&#34;x&#34;:{&#34;visdat&#34;:{&#34;4a8431ae748b&#34;:[&#34;function () &#34;,&#34;plotlyVisDat&#34;]},&#34;cur_data&#34;:&#34;4a8431ae748b&#34;,&#34;attrs&#34;:{&#34;4a8431ae748b&#34;:{&#34;x&#34;:{},&#34;y&#34;:{},&#34;z&#34;:{},&#34;alpha_stroke&#34;:1,&#34;sizes&#34;:[10,100],&#34;spans&#34;:[1,20],&#34;type&#34;:&#34;scatter3d&#34;,&#34;mode&#34;:&#34;markers&#34;,&#34;name&#34;:{},&#34;opacity&#34;:0.8,&#34;inherit&#34;:true}},&#34;layout&#34;:{&#34;margin&#34;:{&#34;b&#34;:40,&#34;l&#34;:60,&#34;t&#34;:25,&#34;r&#34;:10},&#34;scene&#34;:{&#34;xaxis&#34;:{&#34;title&#34;:&#34;D1&#34;},&#34;yaxis&#34;:{&#34;title&#34;:&#34;D2&#34;},&#34;zaxis&#34;:{&#34;title&#34;:&#34;D3&#34;}},&#34;hovermode&#34;:&#34;closest&#34;,&#34;showlegend&#34;:true},&#34;source&#34;:&#34;A&#34;,&#34;config&#34;:{&#34;modeBarButtonsToAdd&#34;:[{&#34;name&#34;:&#34;Collaborate&#34;,&#34;icon&#34;:{&#34;width&#34;:1000,&#34;ascent&#34;:500,&#34;descent&#34;:-50,&#34;path&#34;:&#34;M487 375c7-10 9-23 5-36l-79-259c-3-12-11-23-22-31-11-8-22-12-35-12l-263 0c-15 0-29 5-43 15-13 10-23 23-28 37-5 13-5 25-1 37 0 0 0 3 1 7 1 5 1 8 1 11 0 2 0 4-1 6 0 3-1 5-1 6 1 2 2 4 3 6 1 2 2 4 4 6 2 3 4 5 5 7 5 7 9 16 13 26 4 10 7 19 9 26 0 2 0 5 0 9-1 4-1 6 0 8 0 2 2 5 4 8 3 3 5 5 5 7 4 6 8 15 12 26 4 11 7 19 7 26 1 1 0 4 0 9-1 4-1 7 0 8 1 2 3 5 6 8 4 4 6 6 6 7 4 5 8 13 13 24 4 11 7 20 7 28 1 1 0 4 0 7-1 3-1 6-1 7 0 2 1 4 3 6 1 1 3 4 5 6 2 3 3 5 5 6 1 2 3 5 4 9 2 3 3 7 5 10 1 3 2 6 4 10 2 4 4 7 6 9 2 3 4 5 7 7 3 2 7 3 11 3 3 0 8 0 13-1l0-1c7 2 12 2 14 2l218 0c14 0 25-5 32-16 8-10 10-23 6-37l-79-259c-7-22-13-37-20-43-7-7-19-10-37-10l-248 0c-5 0-9-2-11-5-2-3-2-7 0-12 4-13 18-20 41-20l264 0c5 0 10 2 16 5 5 3 8 6 10 11l85 282c2 5 2 10 2 17 7-3 13-7 17-13z m-304 0c-1-3-1-5 0-7 1-1 3-2 6-2l174 0c2 0 4 1 7 2 2 2 4 4 5 7l6 18c0 3 0 5-1 7-1 1-3 2-6 2l-173 0c-3 0-5-1-8-2-2-2-4-4-4-7z m-24-73c-1-3-1-5 0-7 2-2 3-2 6-2l174 0c2 0 5 0 7 2 3 2 4 4 5 7l6 18c1 2 0 5-1 6-1 2-3 3-5 3l-174 0c-3 0-5-1-7-3-3-1-4-4-5-6z&#34;},&#34;click&#34;:&#34;function(gd) { \n        // is this being viewed in RStudio?\n        if (location.search == &#39;?viewer_pane=1&#39;) {\n          alert(&#39;To learn about plotly for collaboration, visit:\\n https://cpsievert.github.io/plotly_book/plot-ly-for-collaboration.html&#39;);\n        } else {\n          window.open(&#39;https://cpsievert.github.io/plotly_book/plot-ly-for-collaboration.html&#39;, &#39;_blank&#39;);\n        }\n      }&#34;}],&#34;cloud&#34;:false},&#34;data&#34;:[{&#34;x&#34;:[-0.0526937391341063],&#34;y&#34;:[0.0100506056389321],&#34;z&#34;:[0.0145193830867102],&#34;type&#34;:&#34;scatter3d&#34;,&#34;mode&#34;:&#34;markers&#34;,&#34;name&#34;:&#34;bas_gdp&#34;,&#34;opacity&#34;:0.8,&#34;marker&#34;:{&#34;color&#34;:&#34;rgba(31,119,180,1)&#34;,&#34;line&#34;:{&#34;color&#34;:&#34;rgba(31,119,180,1)&#34;}},&#34;error_y&#34;:{&#34;color&#34;:&#34;rgba(31,119,180,1)&#34;},&#34;error_x&#34;:{&#34;color&#34;:&#34;rgba(31,119,180,1)&#34;},&#34;line&#34;:{&#34;color&#34;:&#34;rgba(31,119,180,1)&#34;},&#34;frame&#34;:null},{&#34;x&#34;:[0.276310097100597],&#34;y&#34;:[-0.0205926020788591],&#34;z&#34;:[-0.8554282537917],&#34;type&#34;:&#34;scatter3d&#34;,&#34;mode&#34;:&#34;markers&#34;,&#34;name&#34;:&#34;bas_imp&#34;,&#34;opacity&#34;:0.8,&#34;marker&#34;:{&#34;color&#34;:&#34;rgba(255,127,14,1)&#34;,&#34;line&#34;:{&#34;color&#34;:&#34;rgba(255,127,14,1)&#34;}},&#34;error_y&#34;:{&#34;color&#34;:&#34;rgba(255,127,14,1)&#34;},&#34;error_x&#34;:{&#34;color&#34;:&#34;rgba(255,127,14,1)&#34;},&#34;line&#34;:{&#34;color&#34;:&#34;rgba(255,127,14,1)&#34;},&#34;frame&#34;:null},{&#34;x&#34;:[-0.0444410756700585],&#34;y&#34;:[0.163382309576379],&#34;z&#34;:[-0.351364867892435],&#34;type&#34;:&#34;scatter3d&#34;,&#34;mode&#34;:&#34;markers&#34;,&#34;name&#34;:&#34;bas_ri&#34;,&#34;opacity&#34;:0.8,&#34;marker&#34;:{&#34;color&#34;:&#34;rgba(44,160,44,1)&#34;,&#34;line&#34;:{&#34;color&#34;:&#34;rgba(44,160,44,1)&#34;}},&#34;error_y&#34;:{&#34;color&#34;:&#34;rgba(44,160,44,1)&#34;},&#34;error_x&#34;:{&#34;color&#34;:&#34;rgba(44,160,44,1)&#34;},&#34;line&#34;:{&#34;color&#34;:&#34;rgba(44,160,44,1)&#34;},&#34;frame&#34;:null},{&#34;x&#34;:[0.0715641241847919],&#34;y&#34;:[0.0924901051799827],&#34;z&#34;:[-0.373782917335341],&#34;type&#34;:&#34;scatter3d&#34;,&#34;mode&#34;:&#34;markers&#34;,&#34;name&#34;:&#34;bas_rr&#34;,&#34;opacity&#34;:0.8,&#34;marker&#34;:{&#34;color&#34;:&#34;rgba(214,39,40,1)&#34;,&#34;line&#34;:{&#34;color&#34;:&#34;rgba(214,39,40,1)&#34;}},&#34;error_y&#34;:{&#34;color&#34;:&#34;rgba(214,39,40,1)&#34;},&#34;error_x&#34;:{&#34;color&#34;:&#34;rgba(214,39,40,1)&#34;},&#34;line&#34;:{&#34;color&#34;:&#34;rgba(214,39,40,1)&#34;},&#34;frame&#34;:null},{&#34;x&#34;:[1.11101043032987],&#34;y&#34;:[0.0124259473621813],&#34;z&#34;:[0.105657757218034],&#34;type&#34;:&#34;scatter3d&#34;,&#34;mode&#34;:&#34;markers&#34;,&#34;name&#34;:&#34;bfi_anx&#34;,&#34;opacity&#34;:0.8,&#34;marker&#34;:{&#34;color&#34;:&#34;rgba(148,103,189,1)&#34;,&#34;line&#34;:{&#34;color&#34;:&#34;rgba(148,103,189,1)&#34;}},&#34;error_y&#34;:{&#34;color&#34;:&#34;rgba(148,103,189,1)&#34;},&#34;error_x&#34;:{&#34;color&#34;:&#34;rgba(148,103,189,1)&#34;},&#34;line&#34;:{&#34;color&#34;:&#34;rgba(148,103,189,1)&#34;},&#34;frame&#34;:null},{&#34;x&#34;:[-0.394275492325269],&#34;y&#34;:[0.296806908852657],&#34;z&#34;:[-0.486717849697546],&#34;type&#34;:&#34;scatter3d&#34;,&#34;mode&#34;:&#34;markers&#34;,&#34;name&#34;:&#34;bfi_asser&#34;,&#34;opacity&#34;:0.8,&#34;marker&#34;:{&#34;color&#34;:&#34;rgba(140,86,75,1)&#34;,&#34;line&#34;:{&#34;color&#34;:&#34;rgba(140,86,75,1)&#34;}},&#34;error_y&#34;:{&#34;color&#34;:&#34;rgba(140,86,75,1)&#34;},&#34;error_x&#34;:{&#34;color&#34;:&#34;rgba(140,86,75,1)&#34;},&#34;line&#34;:{&#34;color&#34;:&#34;rgba(140,86,75,1)&#34;},&#34;frame&#34;:null},{&#34;x&#34;:[0.335702487904307],&#34;y&#34;:[-0.240998471298375],&#34;z&#34;:[0.227675720772687],&#34;type&#34;:&#34;scatter3d&#34;,&#34;mode&#34;:&#34;markers&#34;,&#34;name&#34;:&#34;bfi_comp&#34;,&#34;opacity&#34;:0.8,&#34;marker&#34;:{&#34;color&#34;:&#34;rgba(227,119,194,1)&#34;,&#34;line&#34;:{&#34;color&#34;:&#34;rgba(227,119,194,1)&#34;}},&#34;error_y&#34;:{&#34;color&#34;:&#34;rgba(227,119,194,1)&#34;},&#34;error_x&#34;:{&#34;color&#34;:&#34;rgba(227,119,194,1)&#34;},&#34;line&#34;:{&#34;color&#34;:&#34;rgba(227,119,194,1)&#34;},&#34;frame&#34;:null},{&#34;x&#34;:[-0.0365771030833715],&#34;y&#34;:[0.588550050318282],&#34;z&#34;:[0.0486025418165381],&#34;type&#34;:&#34;scatter3d&#34;,&#34;mode&#34;:&#34;markers&#34;,&#34;name&#34;:&#34;bfi_cur&#34;,&#34;opacity&#34;:0.8,&#34;marker&#34;:{&#34;color&#34;:&#34;rgba(127,127,127,1)&#34;,&#34;line&#34;:{&#34;color&#34;:&#34;rgba(127,127,127,1)&#34;}},&#34;error_y&#34;:{&#34;color&#34;:&#34;rgba(127,127,127,1)&#34;},&#34;error_x&#34;:{&#34;color&#34;:&#34;rgba(127,127,127,1)&#34;},&#34;line&#34;:{&#34;color&#34;:&#34;rgba(127,127,127,1)&#34;},&#34;frame&#34;:null},{&#34;x&#34;:[1.22843884213622],&#34;y&#34;:[0.039805228152273],&#34;z&#34;:[0.0860160394708936],&#34;type&#34;:&#34;scatter3d&#34;,&#34;mode&#34;:&#34;markers&#34;,&#34;name&#34;:&#34;bfi_depr&#34;,&#34;opacity&#34;:0.8,&#34;marker&#34;:{&#34;color&#34;:&#34;rgba(188,189,34,1)&#34;,&#34;line&#34;:{&#34;color&#34;:&#34;rgba(188,189,34,1)&#34;}},&#34;error_y&#34;:{&#34;color&#34;:&#34;rgba(188,189,34,1)&#34;},&#34;error_x&#34;:{&#34;color&#34;:&#34;rgba(188,189,34,1)&#34;},&#34;line&#34;:{&#34;color&#34;:&#34;rgba(188,189,34,1)&#34;},&#34;frame&#34;:null},{&#34;x&#34;:[-0.168672500909256],&#34;y&#34;:[0.0146308026021106],&#34;z&#34;:[-0.343214488583721],&#34;type&#34;:&#34;scatter3d&#34;,&#34;mode&#34;:&#34;markers&#34;,&#34;name&#34;:&#34;bfi_energ&#34;,&#34;opacity&#34;:0.8,&#34;marker&#34;:{&#34;color&#34;:&#34;rgba(23,190,207,1)&#34;,&#34;line&#34;:{&#34;color&#34;:&#34;rgba(23,190,207,1)&#34;}},&#34;error_y&#34;:{&#34;color&#34;:&#34;rgba(23,190,207,1)&#34;},&#34;error_x&#34;:{&#34;color&#34;:&#34;rgba(23,190,207,1)&#34;},&#34;line&#34;:{&#34;color&#34;:&#34;rgba(23,190,207,1)&#34;},&#34;frame&#34;:null},{&#34;x&#34;:[-0.158657694463422],&#34;y&#34;:[0.479065661250692],&#34;z&#34;:[0.0487046526673034],&#34;type&#34;:&#34;scatter3d&#34;,&#34;mode&#34;:&#34;markers&#34;,&#34;name&#34;:&#34;bfi_img&#34;,&#34;opacity&#34;:0.8,&#34;marker&#34;:{&#34;color&#34;:&#34;rgba(31,119,180,1)&#34;,&#34;line&#34;:{&#34;color&#34;:&#34;rgba(31,119,180,1)&#34;}},&#34;error_y&#34;:{&#34;color&#34;:&#34;rgba(31,119,180,1)&#34;},&#34;error_x&#34;:{&#34;color&#34;:&#34;rgba(31,119,180,1)&#34;},&#34;line&#34;:{&#34;color&#34;:&#34;rgba(31,119,180,1)&#34;},&#34;frame&#34;:null},{&#34;x&#34;:[0.162942267798098],&#34;y&#34;:[-0.0996510527035331],&#34;z&#34;:[0.585863465075392],&#34;type&#34;:&#34;scatter3d&#34;,&#34;mode&#34;:&#34;markers&#34;,&#34;name&#34;:&#34;bfi_org&#34;,&#34;opacity&#34;:0.8,&#34;marker&#34;:{&#34;color&#34;:&#34;rgba(255,127,14,1)&#34;,&#34;line&#34;:{&#34;color&#34;:&#34;rgba(255,127,14,1)&#34;}},&#34;error_y&#34;:{&#34;color&#34;:&#34;rgba(255,127,14,1)&#34;},&#34;error_x&#34;:{&#34;color&#34;:&#34;rgba(255,127,14,1)&#34;},&#34;line&#34;:{&#34;color&#34;:&#34;rgba(255,127,14,1)&#34;},&#34;frame&#34;:null},{&#34;x&#34;:[-0.18227034537745],&#34;y&#34;:[-0.0534014522021226],&#34;z&#34;:[0.370227064034687],&#34;type&#34;:&#34;scatter3d&#34;,&#34;mode&#34;:&#34;markers&#34;,&#34;name&#34;:&#34;bfi_prod&#34;,&#34;opacity&#34;:0.8,&#34;marker&#34;:{&#34;color&#34;:&#34;rgba(44,160,44,1)&#34;,&#34;line&#34;:{&#34;color&#34;:&#34;rgba(44,160,44,1)&#34;}},&#34;error_y&#34;:{&#34;color&#34;:&#34;rgba(44,160,44,1)&#34;},&#34;error_x&#34;:{&#34;color&#34;:&#34;rgba(44,160,44,1)&#34;},&#34;line&#34;:{&#34;color&#34;:&#34;rgba(44,160,44,1)&#34;},&#34;frame&#34;:null},{&#34;x&#34;:[0.278962015633081],&#34;y&#34;:[-0.262339202999641],&#34;z&#34;:[0.357836811981843],&#34;type&#34;:&#34;scatter3d&#34;,&#34;mode&#34;:&#34;markers&#34;,&#34;name&#34;:&#34;bfi_resp&#34;,&#34;opacity&#34;:0.8,&#34;marker&#34;:{&#34;color&#34;:&#34;rgba(214,39,40,1)&#34;,&#34;line&#34;:{&#34;color&#34;:&#34;rgba(214,39,40,1)&#34;}},&#34;error_y&#34;:{&#34;color&#34;:&#34;rgba(214,39,40,1)&#34;},&#34;error_x&#34;:{&#34;color&#34;:&#34;rgba(214,39,40,1)&#34;},&#34;line&#34;:{&#34;color&#34;:&#34;rgba(214,39,40,1)&#34;},&#34;frame&#34;:null},{&#34;x&#34;:[0.0222446576544222],&#34;y&#34;:[-0.208275966929829],&#34;z&#34;:[0.431583541847511],&#34;type&#34;:&#34;scatter3d&#34;,&#34;mode&#34;:&#34;markers&#34;,&#34;name&#34;:&#34;bfi_respons&#34;,&#34;opacity&#34;:0.8,&#34;marker&#34;:{&#34;color&#34;:&#34;rgba(148,103,189,1)&#34;,&#34;line&#34;:{&#34;color&#34;:&#34;rgba(148,103,189,1)&#34;}},&#34;error_y&#34;:{&#34;color&#34;:&#34;rgba(148,103,189,1)&#34;},&#34;error_x&#34;:{&#34;color&#34;:&#34;rgba(148,103,189,1)&#34;},&#34;line&#34;:{&#34;color&#34;:&#34;rgba(148,103,189,1)&#34;},&#34;frame&#34;:null},{&#34;x&#34;:[0.295403393592883],&#34;y&#34;:[0.457936682388378],&#34;z&#34;:[0.291416206240681],&#34;type&#34;:&#34;scatter3d&#34;,&#34;mode&#34;:&#34;markers&#34;,&#34;name&#34;:&#34;bfi_sens&#34;,&#34;opacity&#34;:0.8,&#34;marker&#34;:{&#34;color&#34;:&#34;rgba(140,86,75,1)&#34;,&#34;line&#34;:{&#34;color&#34;:&#34;rgba(140,86,75,1)&#34;}},&#34;error_y&#34;:{&#34;color&#34;:&#34;rgba(140,86,75,1)&#34;},&#34;error_x&#34;:{&#34;color&#34;:&#34;rgba(140,86,75,1)&#34;},&#34;line&#34;:{&#34;color&#34;:&#34;rgba(140,86,75,1)&#34;},&#34;frame&#34;:null},{&#34;x&#34;:[0.0163816918486288],&#34;y&#34;:[-0.530288208576913],&#34;z&#34;:[0.0308239024329279],&#34;type&#34;:&#34;scatter3d&#34;,&#34;mode&#34;:&#34;markers&#34;,&#34;name&#34;:&#34;bfi_trus&#34;,&#34;opacity&#34;:0.8,&#34;marker&#34;:{&#34;color&#34;:&#34;rgba(227,119,194,1)&#34;,&#34;line&#34;:{&#34;color&#34;:&#34;rgba(227,119,194,1)&#34;}},&#34;error_y&#34;:{&#34;color&#34;:&#34;rgba(227,119,194,1)&#34;},&#34;error_x&#34;:{&#34;color&#34;:&#34;rgba(227,119,194,1)&#34;},&#34;line&#34;:{&#34;color&#34;:&#34;rgba(227,119,194,1)&#34;},&#34;frame&#34;:null},{&#34;x&#34;:[1.05820237674783],&#34;y&#34;:[0.0646970246980621],&#34;z&#34;:[-0.111763245798902],&#34;type&#34;:&#34;scatter3d&#34;,&#34;mode&#34;:&#34;markers&#34;,&#34;name&#34;:&#34;bfi_vol&#34;,&#34;opacity&#34;:0.8,&#34;marker&#34;:{&#34;color&#34;:&#34;rgba(127,127,127,1)&#34;,&#34;line&#34;:{&#34;color&#34;:&#34;rgba(127,127,127,1)&#34;}},&#34;error_y&#34;:{&#34;color&#34;:&#34;rgba(127,127,127,1)&#34;},&#34;error_x&#34;:{&#34;color&#34;:&#34;rgba(127,127,127,1)&#34;},&#34;line&#34;:{&#34;color&#34;:&#34;rgba(127,127,127,1)&#34;},&#34;frame&#34;:null},{&#34;x&#34;:[1.14104766481683],&#34;y&#34;:[-0.0214911404083726],&#34;z&#34;:[-0.0684767269811899],&#34;type&#34;:&#34;scatter3d&#34;,&#34;mode&#34;:&#34;markers&#34;,&#34;name&#34;:&#34;bis&#34;,&#34;opacity&#34;:0.8,&#34;marker&#34;:{&#34;color&#34;:&#34;rgba(188,189,34,1)&#34;,&#34;line&#34;:{&#34;color&#34;:&#34;rgba(188,189,34,1)&#34;}},&#34;error_y&#34;:{&#34;color&#34;:&#34;rgba(188,189,34,1)&#34;},&#34;error_x&#34;:{&#34;color&#34;:&#34;rgba(188,189,34,1)&#34;},&#34;line&#34;:{&#34;color&#34;:&#34;rgba(188,189,34,1)&#34;},&#34;frame&#34;:null},{&#34;x&#34;:[-0.500748547260815],&#34;y&#34;:[0.0183973932587392],&#34;z&#34;:[0.068167857312488],&#34;type&#34;:&#34;scatter3d&#34;,&#34;mode&#34;:&#34;markers&#34;,&#34;name&#34;:&#34;cms&#34;,&#34;opacity&#34;:0.8,&#34;marker&#34;:{&#34;color&#34;:&#34;rgba(23,190,207,1)&#34;,&#34;line&#34;:{&#34;color&#34;:&#34;rgba(23,190,207,1)&#34;}},&#34;error_y&#34;:{&#34;color&#34;:&#34;rgba(23,190,207,1)&#34;},&#34;error_x&#34;:{&#34;color&#34;:&#34;rgba(23,190,207,1)&#34;},&#34;line&#34;:{&#34;color&#34;:&#34;rgba(23,190,207,1)&#34;},&#34;frame&#34;:null},{&#34;x&#34;:[0.940878825618137],&#34;y&#34;:[-0.429351838067984],&#34;z&#34;:[-0.171670259793936],&#34;type&#34;:&#34;scatter3d&#34;,&#34;mode&#34;:&#34;markers&#34;,&#34;name&#34;:&#34;fffs&#34;,&#34;opacity&#34;:0.8,&#34;marker&#34;:{&#34;color&#34;:&#34;rgba(31,119,180,1)&#34;,&#34;line&#34;:{&#34;color&#34;:&#34;rgba(31,119,180,1)&#34;}},&#34;error_y&#34;:{&#34;color&#34;:&#34;rgba(31,119,180,1)&#34;},&#34;error_x&#34;:{&#34;color&#34;:&#34;rgba(31,119,180,1)&#34;},&#34;line&#34;:{&#34;color&#34;:&#34;rgba(31,119,180,1)&#34;},&#34;frame&#34;:null},{&#34;x&#34;:[0.239475473919484],&#34;y&#34;:[0.465529954355441],&#34;z&#34;:[-0.0100739094355942],&#34;type&#34;:&#34;scatter3d&#34;,&#34;mode&#34;:&#34;markers&#34;,&#34;name&#34;:&#34;ffmq_bs&#34;,&#34;opacity&#34;:0.8,&#34;marker&#34;:{&#34;color&#34;:&#34;rgba(255,127,14,1)&#34;,&#34;line&#34;:{&#34;color&#34;:&#34;rgba(255,127,14,1)&#34;}},&#34;error_y&#34;:{&#34;color&#34;:&#34;rgba(255,127,14,1)&#34;},&#34;error_x&#34;:{&#34;color&#34;:&#34;rgba(255,127,14,1)&#34;},&#34;line&#34;:{&#34;color&#34;:&#34;rgba(255,127,14,1)&#34;},&#34;frame&#34;:null},{&#34;x&#34;:[-0.477807197118049],&#34;y&#34;:[0.287387962803004],&#34;z&#34;:[0.0650926058484695],&#34;type&#34;:&#34;scatter3d&#34;,&#34;mode&#34;:&#34;markers&#34;,&#34;name&#34;:&#34;ffmq_dscr&#34;,&#34;opacity&#34;:0.8,&#34;marker&#34;:{&#34;color&#34;:&#34;rgba(44,160,44,1)&#34;,&#34;line&#34;:{&#34;color&#34;:&#34;rgba(44,160,44,1)&#34;}},&#34;error_y&#34;:{&#34;color&#34;:&#34;rgba(44,160,44,1)&#34;},&#34;error_x&#34;:{&#34;color&#34;:&#34;rgba(44,160,44,1)&#34;},&#34;line&#34;:{&#34;color&#34;:&#34;rgba(44,160,44,1)&#34;},&#34;frame&#34;:null},{&#34;x&#34;:[-0.579069156770136],&#34;y&#34;:[-0.378881107075204],&#34;z&#34;:[-0.0446274503226854],&#34;type&#34;:&#34;scatter3d&#34;,&#34;mode&#34;:&#34;markers&#34;,&#34;name&#34;:&#34;ffmq_jdgmnt&#34;,&#34;opacity&#34;:0.8,&#34;marker&#34;:{&#34;color&#34;:&#34;rgba(214,39,40,1)&#34;,&#34;line&#34;:{&#34;color&#34;:&#34;rgba(214,39,40,1)&#34;}},&#34;error_y&#34;:{&#34;color&#34;:&#34;rgba(214,39,40,1)&#34;},&#34;error_x&#34;:{&#34;color&#34;:&#34;rgba(214,39,40,1)&#34;},&#34;line&#34;:{&#34;color&#34;:&#34;rgba(214,39,40,1)&#34;},&#34;frame&#34;:null},{&#34;x&#34;:[-0.656930632902125],&#34;y&#34;:[-0.155055915668114],&#34;z&#34;:[-0.308032594498214],&#34;type&#34;:&#34;scatter3d&#34;,&#34;mode&#34;:&#34;markers&#34;,&#34;name&#34;:&#34;ffmq_rct&#34;,&#34;opacity&#34;:0.8,&#34;marker&#34;:{&#34;color&#34;:&#34;rgba(148,103,189,1)&#34;,&#34;line&#34;:{&#34;color&#34;:&#34;rgba(148,103,189,1)&#34;}},&#34;error_y&#34;:{&#34;color&#34;:&#34;rgba(148,103,189,1)&#34;},&#34;error_x&#34;:{&#34;color&#34;:&#34;rgba(148,103,189,1)&#34;},&#34;line&#34;:{&#34;color&#34;:&#34;rgba(148,103,189,1)&#34;},&#34;frame&#34;:null},{&#34;x&#34;:[-0.460763257202939],&#34;y&#34;:[-0.0445801211010356],&#34;z&#34;:[0.361962534755171],&#34;type&#34;:&#34;scatter3d&#34;,&#34;mode&#34;:&#34;markers&#34;,&#34;name&#34;:&#34;ffmq_wrnss&#34;,&#34;opacity&#34;:0.8,&#34;marker&#34;:{&#34;color&#34;:&#34;rgba(140,86,75,1)&#34;,&#34;line&#34;:{&#34;color&#34;:&#34;rgba(140,86,75,1)&#34;}},&#34;error_y&#34;:{&#34;color&#34;:&#34;rgba(140,86,75,1)&#34;},&#34;error_x&#34;:{&#34;color&#34;:&#34;rgba(140,86,75,1)&#34;},&#34;line&#34;:{&#34;color&#34;:&#34;rgba(140,86,75,1)&#34;},&#34;frame&#34;:null},{&#34;x&#34;:[-0.412729240707344],&#34;y&#34;:[0.0403878273796323],&#34;z&#34;:[-0.168222164008848],&#34;type&#34;:&#34;scatter3d&#34;,&#34;mode&#34;:&#34;markers&#34;,&#34;name&#34;:&#34;frbrg&#34;,&#34;opacity&#34;:0.8,&#34;marker&#34;:{&#34;color&#34;:&#34;rgba(227,119,194,1)&#34;,&#34;line&#34;:{&#34;color&#34;:&#34;rgba(227,119,194,1)&#34;}},&#34;error_y&#34;:{&#34;color&#34;:&#34;rgba(227,119,194,1)&#34;},&#34;error_x&#34;:{&#34;color&#34;:&#34;rgba(227,119,194,1)&#34;},&#34;line&#34;:{&#34;color&#34;:&#34;rgba(227,119,194,1)&#34;},&#34;frame&#34;:null},{&#34;x&#34;:[0.187230622812134],&#34;y&#34;:[0.462884884191886],&#34;z&#34;:[0.054015633133116],&#34;type&#34;:&#34;scatter3d&#34;,&#34;mode&#34;:&#34;markers&#34;,&#34;name&#34;:&#34;kms_bs&#34;,&#34;opacity&#34;:0.8,&#34;marker&#34;:{&#34;color&#34;:&#34;rgba(127,127,127,1)&#34;,&#34;line&#34;:{&#34;color&#34;:&#34;rgba(127,127,127,1)&#34;}},&#34;error_y&#34;:{&#34;color&#34;:&#34;rgba(127,127,127,1)&#34;},&#34;error_x&#34;:{&#34;color&#34;:&#34;rgba(127,127,127,1)&#34;},&#34;line&#34;:{&#34;color&#34;:&#34;rgba(127,127,127,1)&#34;},&#34;frame&#34;:null},{&#34;x&#34;:[-0.472875681178277],&#34;y&#34;:[0.323285039440176],&#34;z&#34;:[0.0413421294268492],&#34;type&#34;:&#34;scatter3d&#34;,&#34;mode&#34;:&#34;markers&#34;,&#34;name&#34;:&#34;kms_dscr&#34;,&#34;opacity&#34;:0.8,&#34;marker&#34;:{&#34;color&#34;:&#34;rgba(188,189,34,1)&#34;,&#34;line&#34;:{&#34;color&#34;:&#34;rgba(188,189,34,1)&#34;}},&#34;error_y&#34;:{&#34;color&#34;:&#34;rgba(188,189,34,1)&#34;},&#34;error_x&#34;:{&#34;color&#34;:&#34;rgba(188,189,34,1)&#34;},&#34;line&#34;:{&#34;color&#34;:&#34;rgba(188,189,34,1)&#34;},&#34;frame&#34;:null},{&#34;x&#34;:[-0.590465597198597],&#34;y&#34;:[-0.49398527882312],&#34;z&#34;:[-0.0630515392528261],&#34;type&#34;:&#34;scatter3d&#34;,&#34;mode&#34;:&#34;markers&#34;,&#34;name&#34;:&#34;kms_jdgmnt&#34;,&#34;opacity&#34;:0.8,&#34;marker&#34;:{&#34;color&#34;:&#34;rgba(23,190,207,1)&#34;,&#34;line&#34;:{&#34;color&#34;:&#34;rgba(23,190,207,1)&#34;}},&#34;error_y&#34;:{&#34;color&#34;:&#34;rgba(23,190,207,1)&#34;},&#34;error_x&#34;:{&#34;color&#34;:&#34;rgba(23,190,207,1)&#34;},&#34;line&#34;:{&#34;color&#34;:&#34;rgba(23,190,207,1)&#34;},&#34;frame&#34;:null},{&#34;x&#34;:[-0.577353245627685],&#34;y&#34;:[-0.142162342215193],&#34;z&#34;:[0.416898598641502],&#34;type&#34;:&#34;scatter3d&#34;,&#34;mode&#34;:&#34;markers&#34;,&#34;name&#34;:&#34;kms_wrnss&#34;,&#34;opacity&#34;:0.8,&#34;marker&#34;:{&#34;color&#34;:&#34;rgba(31,119,180,1)&#34;,&#34;line&#34;:{&#34;color&#34;:&#34;rgba(31,119,180,1)&#34;}},&#34;error_y&#34;:{&#34;color&#34;:&#34;rgba(31,119,180,1)&#34;},&#34;error_x&#34;:{&#34;color&#34;:&#34;rgba(31,119,180,1)&#34;},&#34;line&#34;:{&#34;color&#34;:&#34;rgba(31,119,180,1)&#34;},&#34;frame&#34;:null},{&#34;x&#34;:[-0.183082184642792],&#34;y&#34;:[0.36654247319163],&#34;z&#34;:[-0.0996917953104918],&#34;type&#34;:&#34;scatter3d&#34;,&#34;mode&#34;:&#34;markers&#34;,&#34;name&#34;:&#34;mms_mindf&#34;,&#34;opacity&#34;:0.8,&#34;marker&#34;:{&#34;color&#34;:&#34;rgba(255,127,14,1)&#34;,&#34;line&#34;:{&#34;color&#34;:&#34;rgba(255,127,14,1)&#34;}},&#34;error_y&#34;:{&#34;color&#34;:&#34;rgba(255,127,14,1)&#34;},&#34;error_x&#34;:{&#34;color&#34;:&#34;rgba(255,127,14,1)&#34;},&#34;line&#34;:{&#34;color&#34;:&#34;rgba(255,127,14,1)&#34;},&#34;frame&#34;:null},{&#34;x&#34;:[0.392223448557579],&#34;y&#34;:[-0.830449316658233],&#34;z&#34;:[-0.494002684000161],&#34;type&#34;:&#34;scatter3d&#34;,&#34;mode&#34;:&#34;markers&#34;,&#34;name&#34;:&#34;mms_mindl&#34;,&#34;opacity&#34;:0.8,&#34;marker&#34;:{&#34;color&#34;:&#34;rgba(44,160,44,1)&#34;,&#34;line&#34;:{&#34;color&#34;:&#34;rgba(44,160,44,1)&#34;}},&#34;error_y&#34;:{&#34;color&#34;:&#34;rgba(44,160,44,1)&#34;},&#34;error_x&#34;:{&#34;color&#34;:&#34;rgba(44,160,44,1)&#34;},&#34;line&#34;:{&#34;color&#34;:&#34;rgba(44,160,44,1)&#34;},&#34;frame&#34;:null},{&#34;x&#34;:[-0.506106188562398],&#34;y&#34;:[-0.0411941809001068],&#34;z&#34;:[0.29559480225294],&#34;type&#34;:&#34;scatter3d&#34;,&#34;mode&#34;:&#34;markers&#34;,&#34;name&#34;:&#34;ms&#34;,&#34;opacity&#34;:0.8,&#34;marker&#34;:{&#34;color&#34;:&#34;rgba(214,39,40,1)&#34;,&#34;line&#34;:{&#34;color&#34;:&#34;rgba(214,39,40,1)&#34;}},&#34;error_y&#34;:{&#34;color&#34;:&#34;rgba(214,39,40,1)&#34;},&#34;error_x&#34;:{&#34;color&#34;:&#34;rgba(214,39,40,1)&#34;},&#34;line&#34;:{&#34;color&#34;:&#34;rgba(214,39,40,1)&#34;},&#34;frame&#34;:null},{&#34;x&#34;:[-0.717551484233003],&#34;y&#34;:[-0.403259078925507],&#34;z&#34;:[0.11622904674143],&#34;type&#34;:&#34;scatter3d&#34;,&#34;mode&#34;:&#34;markers&#34;,&#34;name&#34;:&#34;phlms_ccpt&#34;,&#34;opacity&#34;:0.8,&#34;marker&#34;:{&#34;color&#34;:&#34;rgba(148,103,189,1)&#34;,&#34;line&#34;:{&#34;color&#34;:&#34;rgba(148,103,189,1)&#34;}},&#34;error_y&#34;:{&#34;color&#34;:&#34;rgba(148,103,189,1)&#34;},&#34;error_x&#34;:{&#34;color&#34;:&#34;rgba(148,103,189,1)&#34;},&#34;line&#34;:{&#34;color&#34;:&#34;rgba(148,103,189,1)&#34;},&#34;frame&#34;:null},{&#34;x&#34;:[0.108082136972473],&#34;y&#34;:[0.39787527023927],&#34;z&#34;:[0.0864268859196207],&#34;type&#34;:&#34;scatter3d&#34;,&#34;mode&#34;:&#34;markers&#34;,&#34;name&#34;:&#34;phlms_wrnss&#34;,&#34;opacity&#34;:0.8,&#34;marker&#34;:{&#34;color&#34;:&#34;rgba(140,86,75,1)&#34;,&#34;line&#34;:{&#34;color&#34;:&#34;rgba(140,86,75,1)&#34;}},&#34;error_y&#34;:{&#34;color&#34;:&#34;rgba(140,86,75,1)&#34;},&#34;error_x&#34;:{&#34;color&#34;:&#34;rgba(140,86,75,1)&#34;},&#34;line&#34;:{&#34;color&#34;:&#34;rgba(140,86,75,1)&#34;},&#34;frame&#34;:null},{&#34;x&#34;:[-0.693030193260395],&#34;y&#34;:[-0.226174854247565],&#34;z&#34;:[-0.1545364339732],&#34;type&#34;:&#34;scatter3d&#34;,&#34;mode&#34;:&#34;markers&#34;,&#34;name&#34;:&#34;smq&#34;,&#34;opacity&#34;:0.8,&#34;marker&#34;:{&#34;color&#34;:&#34;rgba(227,119,194,1)&#34;,&#34;line&#34;:{&#34;color&#34;:&#34;rgba(227,119,194,1)&#34;}},&#34;error_y&#34;:{&#34;color&#34;:&#34;rgba(227,119,194,1)&#34;},&#34;error_x&#34;:{&#34;color&#34;:&#34;rgba(227,119,194,1)&#34;},&#34;line&#34;:{&#34;color&#34;:&#34;rgba(227,119,194,1)&#34;},&#34;frame&#34;:null}],&#34;highlight&#34;:{&#34;on&#34;:&#34;plotly_click&#34;,&#34;persistent&#34;:false,&#34;dynamic&#34;:false,&#34;selectize&#34;:false,&#34;opacityDim&#34;:0.2,&#34;selected&#34;:{&#34;opacity&#34;:1},&#34;debounce&#34;:0},&#34;base_url&#34;:&#34;https://plot.ly&#34;},&#34;evals&#34;:[&#34;config.modeBarButtonsToAdd.0.click&#34;],&#34;jsHooks&#34;:[]}&lt;/script&gt;
&lt;/div&gt;
&lt;div id=&#34;interpretation-of-a-mds-plot&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Interpretation of a MDS plot&lt;/h2&gt;
&lt;p&gt;In their introduction to Multidimensional Scaling Kruskal and Wish recommend that a MDS plot should be interpreted by applying the following rule (generalised from their example of Morse code): &amp;quot; Pick some point which is peripheral, that is, which lies at the outermost edge of the configuration. Ask yourself what is common to this point and its nearest neighbors, and how they differ from the points at the opposite edge of the configuration. Then repeat this process, using other peripheral points.&amp;quot;&lt;/p&gt;
&lt;p&gt;In a two dimensional plot it can be beneficial to first examine the x and y axis. This can yield important insight into the structure of the points. Same holds true for a 3-dimensional solution. We first look at x, y, and z.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Landscape and Well-Being: Using Psychology to Inform Urban Planning</title>
      <link>/talk/blue_welbeing/</link>
      <pubDate>Sun, 01 Jan 2017 00:00:00 +1300</pubDate>
      
      <guid>/talk/blue_welbeing/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Person-culture fit and well-being</title>
      <link>/talk/person_culture_fit/</link>
      <pubDate>Sun, 01 Jan 2017 00:00:00 +1300</pubDate>
      
      <guid>/talk/person_culture_fit/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Rituals, Repetitiveness and Cognitive Load: A Competitive Test of Ritual Benefits for Stress</title>
      <link>/talk/rituals_anxiety/</link>
      <pubDate>Sun, 01 Jan 2017 00:00:00 +1300</pubDate>
      
      <guid>/talk/rituals_anxiety/</guid>
      <description></description>
    </item>
    
    <item>
      <title>The Complexities of “Minding the Gap”: Perceived Discrepancies Between Values and Behavior Affect Well-Being</title>
      <link>/publication/values/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/publication/values/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
